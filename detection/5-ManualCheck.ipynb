{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cc3753",
   "metadata": {},
   "source": [
    "## Import necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d089cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uid-1204\\AppData\\Local\\anaconda3\\envs\\bigfishLive\\lib\\site-packages\\bigfish\\segmentation\\nuc_segmentation.py:16: FutureWarning: The `skimage.morphology.selem` module is deprecated and will be removed in scikit-image 1.0 (`skimage.morphology.selem` has been moved to `skimage.morphology.footprints`).\n",
      "  from skimage.morphology.selem import disk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import napari\n",
    "import trackpy as tp\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "import bigfish\n",
    "import bigfish.plot as plot\n",
    "import bigfish.stack as stack\n",
    "import bigfish.detection as detection\n",
    "import bigfish.multistack as multistack\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from random import sample \n",
    "pd.set_option('display.max_rows', 2000)\n",
    "from copy import deepcopy\n",
    "from dask.array.image import imread as imr\n",
    "from bigfish.detection.utils import get_object_radius_pixel\n",
    "\n",
    "from pathlib import Path\n",
    "from napari.layers import Image\n",
    "from magicgui import magicgui, magic_factory, widgets\n",
    "from magicgui.widgets import Table\n",
    "import bigfish.segmentation as segmentation\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.morphology.selem import disk\n",
    "from napari.types import ImageData, LabelsData\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6823fdb",
   "metadata": {},
   "source": [
    "## Specify voxel and object size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e6c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelRadius = (600, 121, 121)\n",
    "objectRadius = (600, 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ede8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def bi_exp(x, a, b, c, d):\n",
    "    return (a * np.exp(-b * x)) + (c * np.exp(-d * x))\n",
    "\n",
    "def trip_exp(x, a, b, c, d, e, f):\n",
    "    return ((a * np.exp(-b * x)) + (c * np.exp(-d * x)) + (e * np.exp(-f * x)))\n",
    "\n",
    "def getBleachCorrected(stackCell, model='bi'):\n",
    "    axes = tuple([i for i in range(len(stackCell.shape))])\n",
    "    I_mean = np.mean(stackCell, axis=axes[1:])\n",
    "    timePoints = np.arange(stackCell.shape[0])\n",
    "    \n",
    "    if model=='bi':\n",
    "        coeffsExp, _ = curve_fit(bi_exp, timePoints, I_mean, maxfev=50000)\n",
    "        f_ = np.vectorize(bi_exp)(timePoints, *coeffsExp)\n",
    "    elif model=='tri':\n",
    "        coeffsExp, _ = curve_fit(trip_exp, timePoints, I_mean, maxfev=50000)\n",
    "        f_ = np.vectorize(trip_exp)(timePoints, *coeffsExp)\n",
    "    \n",
    "    \n",
    "    f = f_ / np.max(f_)\n",
    "    f = f.reshape(-1, 1, 1, 1)\n",
    "    imagesCorrected = (stackCell / f).astype(np.uint16)\n",
    "\n",
    "    # calculate r squared\n",
    "    residuals = I_mean - f_\n",
    "    ss_res = np.sum(residuals ** 2)\n",
    "    ss_tot = np.sum((I_mean - np.mean(I_mean)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    r_squared_exp = np.array(r_squared)\n",
    "    return imagesCorrected, r_squared_exp, I_mean\n",
    "\n",
    "def getImagesAndSpotList(sequenceCell, selectedThreshold, voxelRadius, objectRadius, sampling=10):\n",
    "    images=[]    \n",
    "    spots_list=[]\n",
    "    MaxTimePoint = sequenceCell.shape[0]\n",
    "\n",
    "    spot_radius_px = detection.get_object_radius_pixel(\n",
    "        voxel_size_nm=voxelRadius, \n",
    "        object_radius_nm=objectRadius, \n",
    "        ndim=3)\n",
    "\n",
    "    for t in range(1,MaxTimePoint,sampling):\n",
    "        rna = np.array(sequenceCell[t])\n",
    "        images.append(rna)\n",
    "\n",
    "        # LoG filter\n",
    "        rna_log = stack.log_filter(rna, sigma=spot_radius_px)\n",
    "\n",
    "        # local maximum detection\n",
    "        mask = detection.local_maximum_detection(rna_log, min_distance=spot_radius_px)\n",
    "\n",
    "        # thresholding\n",
    "        threshold = detection.automated_threshold_setting(rna_log, mask)\n",
    "        spots_, _ = detection.spots_thresholding(rna_log, mask, float(selectedThreshold))\n",
    "        spots_list.append(spots_)\n",
    "    n=len(images)\n",
    "    print(\"Total number of images : \"+str(n))\n",
    "    return images, spots_list, n\n",
    "\n",
    "def choose_home_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    file_path = filedialog.askdirectory(initialdir= \"/\", title='Please select a directory')  # Open file dialog\n",
    "\n",
    "    root.destroy()  # Close the tkinter window\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def findFitstTxFrame(blurClusters):\n",
    "    for i in range(len(blurClusters)):  \n",
    "        if blurClusters[i].size!=0:\n",
    "            return i\n",
    "\n",
    "def findSpotBrightness2D(spotList, blurImage):\n",
    "    meanBrightness = []\n",
    "    for hh in range(len(spotList)):\n",
    "#         z = spotList[hh,0]\n",
    "        y = spotList[hh,0]\n",
    "        x = spotList[hh,1]\n",
    "        meanBrightness.append(np.sum(np.array(blurImage[y-3:y+4,x-3:x+4])))\n",
    "    return meanBrightness\n",
    "\n",
    "from runBigfishDetection import getSpotAndClusters\n",
    "def mergeTxSites(clusterFrames):\n",
    "    newCluster = np.zeros((1,5))\n",
    "    newCluster[0,0:3]=clusterFrames[np.argmax(clusterFrames[:,3]), 0:3]\n",
    "    newCluster[0,3]= np.sum(clusterFrames[:,3])\n",
    "    return newCluster\n",
    "\n",
    "\n",
    "def df2List(potentialTxs):\n",
    "    newClusterFrame=[]\n",
    "    \n",
    "    for i in range(len(potentialTxs)):\n",
    "        if potentialTxs.iloc[i,1:].sum()!=0:\n",
    "            newClusterFrame.append(np.array(potentialTxs.iloc[i,1:]).reshape((1, 5)))\n",
    "        else:\n",
    "            newClusterFrame.append(np.array([], dtype=np.int64).reshape((0, 5)))\n",
    "    return newClusterFrame\n",
    "def findSpotBrightness(spotList, sequenceCell):\n",
    "    meanBrightness = []\n",
    "    for hh in range(len(spotList)):\n",
    "        z = spotList[hh,0]\n",
    "        y = spotList[hh,1]\n",
    "        x = spotList[hh,2]\n",
    "        meanBrightness.append(np.sum(np.array(sequenceCell[z-3:z+4,y-3:y+4,x-3:x+4])))\n",
    "    return meanBrightness\n",
    "\n",
    "def findMissingTxSite(selectedThreshold, sequenceCell, reference_spot,cellNumber,Tx_label_clean, t, lastLocation, bETA, gAMA=5, numCs=2, rCls=600, vR=(600,121,121), oR=(400,202,202), reorderyn = False):\n",
    "    spots_T, clusters_T, _ = getSpotAndClusters(sequenceCell,\n",
    "                                             reference_spot, \n",
    "                                             cellnumber=cellNumber, \n",
    "                                             startTime=t,\n",
    "                                             stopTime=t+1, \n",
    "                                             thresholdManual=selectedThreshold, \n",
    "                                             beta=bETA, \n",
    "                                             gamma=gAMA,\n",
    "                                             numberOfSpots=numCs,\n",
    "                                             radiusCluster=rCls, \n",
    "                                             voxelSize=vR, \n",
    "                                             objectSize=oR,\n",
    "                                             reorder=reorderyn,\n",
    "                                             extensionMov='.tif',\n",
    "                                             showProgress=False)\n",
    "#     print(spots_T, clusters_T)\n",
    "#     print('last loc: ', lastLocation)\n",
    "    if len(clusters_T[0])>3*len(spots_T[0]):\n",
    "        print(len(spots_T[0]))\n",
    "        print(len(clusters_T[0]))\n",
    "        print('beta very low! Increase the beta!')\n",
    "        \n",
    "    mask_in_frames = Tx_label_clean[clusters_T[0][:,1], clusters_T[0][:,2]]\n",
    "#     print(clusters_T)\n",
    "    mask_in_frames = Tx_label_clean[clusters_T[0][:,1], clusters_T[0][:,2]]\n",
    "    missingTx0 = clusters_T[0][mask_in_frames]\n",
    "\n",
    "#     print(missingTx0)\n",
    "    if missingTx0.size!=0:\n",
    "        idxs = np.where(np.sum(np.abs(missingTx0[:,0:3] - lastLocation), axis=1)<=10)[0]\n",
    "        if idxs.size!=0:\n",
    "            missingTx = mergeTxSites(missingTx0[idxs,:])\n",
    "            return missingTx\n",
    "        else:\n",
    "            print('not found (not close to last location)')\n",
    "            return missingTx0[idxs,:]\n",
    "    else:\n",
    "        print('not found (not in mask)')\n",
    "        return missingTx0\n",
    "\n",
    "def df2ClusterData(potentialTxs):\n",
    "    newClusterFrame=[]\n",
    "    \n",
    "    for i in range(MaxTimePoint):\n",
    "        if np.sum(potentialTxs.loc[potentialTxs['frame']==i][['z','y', 'x','mrna']]).sum()!=0:\n",
    "            clustersFound = np.array(potentialTxs.loc[potentialTxs['frame']==i][['z','y', 'x','mrna', 'cluster_id']])\n",
    "            lsize=sum(np.sum(clustersFound[:,:-1], axis=1).astype(bool))\n",
    "            newClusterFrame.append(clustersFound[np.sum(clustersFound[:,:-1], axis=1).astype(bool)].reshape((lsize, 5)))\n",
    "        else:\n",
    "            newClusterFrame.append(np.array([], dtype=np.int64).reshape((0, 5)))\n",
    "    return newClusterFrame\n",
    "\n",
    "def makeTrackData(potentialTxsFinal):\n",
    "    newClusterFrame = df2ClusterData(potentialTxsFinal)\n",
    "    columnsid=['frame']\n",
    "    for clidu in np.unique(potentialTxsFinal.cluster_id):\n",
    "        if clidu ==0:\n",
    "            Tx1 = potentialTxsFinal[potentialTxsFinal['cluster_id']==0]\n",
    "            tableToDisplay = pd.DataFrame(Tx1.loc[:,['frame', 'mrna']].astype(int))\n",
    "            columnsid.append('mrna_'+str(clidu))\n",
    "        else:\n",
    "            Tx2 = potentialTxsFinal[potentialTxsFinal['cluster_id']==clidu]\n",
    "            tableToDisplay = pd.concat([tableToDisplay , Tx2.loc[:,['mrna']].astype(int)], axis=1)\n",
    "            columnsid.append('mrna_'+str(clidu))\n",
    "    tableToDisplay.columns = columnsid\n",
    "    columnHd = tableToDisplay.columns[1:]\n",
    "    dftracksFinal = pd.concat([potentialTxsFinal['cluster_id'],potentialTxsFinal['frame'],potentialTxsFinal.loc[:,['y','x']]], axis=1)\n",
    "    dd=dftracksFinal.sort_values(by=['cluster_id', 'frame'])\n",
    "    tracks_data = np.asarray(dd)\n",
    "    dftracksFinal = dftracksFinal[np.sum(dftracksFinal.iloc[:,2:],axis=1)!=0]\n",
    "    return columnHd, newClusterFrame, tableToDisplay, dftracksFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b7c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setProbability(part1Test):\n",
    "    probTx = np.zeros((900,1))\n",
    "    windowSize=5\n",
    "    start=windowSize//2\n",
    "    stop=MaxTimePoint-start\n",
    "\n",
    "    for t in part1Test.frame.values:\n",
    "        for ii in np.arange(-(windowSize-1)//2,(windowSize+1)//2,1):\n",
    "            probTx[t+ii] = probTx[t+ii]+(1/9)\n",
    "    return probTx\n",
    "\n",
    "def findDetectedTxs(clsFrm, part1Test, MaxTimePoint, probTx):\n",
    "    potentialTxs = pd.DataFrame(np.zeros([MaxTimePoint, 1+3+1]), columns=['frame', 'z', 'y', 'x', 'mrna'])\n",
    "    potentialTxs['frame']= np.arange(0,MaxTimePoint,1)\n",
    "    lastLocation = clsFrm[findFitstTxFrame(clsFrm)][:,1:3]\n",
    "    for frameNumber in range(0,MaxTimePoint):\n",
    "        clsFrmSrtd=clsFrm[frameNumber][np.argsort(clsFrm[frameNumber][:,0]),:]\n",
    "        if len(clsFrm[frameNumber])>2:\n",
    "    #         print('more than two found at', frameNumber)\n",
    "            idx = np.where(np.sum(np.power(clsFrmSrtd[:,1:3]-np.array(lastLocation),2), axis=1)<=60)[0]\n",
    "            if idx.size!=0:\n",
    "                validIdxs=np.unique(idx)\n",
    "                clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[validIdxs,:])\n",
    "    #             print('merged')\n",
    "            elif idx.size==0:\n",
    "                t = part1Test.frame.values[np.argmin(abs(part1Test.frame.values-frameNumber))]\n",
    "                if np.abs(t-frameNumber)<=5:        \n",
    "                    particleCoordinates = np.asarray(part1Test[part1Test['frame']==t])[0][:2]\n",
    "                    print('possible error, looking for hct at t', t)\n",
    "                    idxnew = np.where(np.sum(np.power(clsFrmSrtd[:,1:3]-particleCoordinates,2), axis=1)<=70)[0]\n",
    "                    if idxnew.size!=0:\n",
    "                        clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[idxnew,:])\n",
    "                        print('new tx found', frameNumber)\n",
    "                        potentialTxs.loc[potentialTxs['frame']==frameNumber,['z', 'y', 'x', 'mrna']] = clsFrm[frameNumber][0][0:4]\n",
    "                        lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "                    if idxnew.size==0:\n",
    "                        if probTx[frameNumber]>0.7:\n",
    "                            idxnew2 = np.where(np.sum(np.abs(clsFrmSrtd[:,1:3]-particleCoordinates), axis=1)<=70)[0]\n",
    "                            clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[idxnew2,:])\n",
    "                            print('new tx added regardless since high prob', frameNumber)\n",
    "                            potentialTxs.loc[potentialTxs['frame']==frameNumber,['z', 'y', 'x', 'mrna']] = clsFrm[frameNumber][0][0:4]\n",
    "                            lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "\n",
    "        if len(clsFrm[frameNumber])==1:\n",
    "    #         print('only one tx found', frameNumber)\n",
    "            potentialTxs.loc[potentialTxs['frame']==frameNumber,['z', 'y', 'x', 'mrna']] = clsFrm[frameNumber][0][0:4]\n",
    "            lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "    #         print('added')\n",
    "\n",
    "        elif len(clsFrm[frameNumber])==2:\n",
    "    #         print('frame :',frameNumber, ' lastloc ',lastLocation)\n",
    "            idx = np.where(np.sum(np.power(clsFrmSrtd[:,1:3]-np.array(lastLocation),2), axis=1)<=60)[0]\n",
    "    #         print('2 clusters found', frameNumber, 'idxs :' ,idx)\n",
    "            if idx.size!=0:\n",
    "                validIdxs=np.unique(idx)\n",
    "    #             print('merging sites')\n",
    "                clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[validIdxs,:])\n",
    "                potentialTxs.loc[potentialTxs['frame']==frameNumber, ['z', 'y', 'x']]=clsFrm[frameNumber][:, 0:3]\n",
    "                potentialTxs.loc[potentialTxs['frame']==frameNumber, ['mrna']] = clsFrm[frameNumber][:,3]\n",
    "                lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "            elif idx.size==0:\n",
    "                t = part1Test.frame.values[np.argmin(abs(part1Test.frame.values-frameNumber))]\n",
    "                if np.abs(t-frameNumber)<=5:        \n",
    "                    particleCoordinates = np.asarray(part1Test[part1Test['frame']==t])[0][:2]\n",
    "                    print('possible error, looking for hct at t', t)\n",
    "                    idxnew = np.where(np.sum(np.power(clsFrmSrtd[:,1:3]-particleCoordinates,2), axis=1)<=25)[0]\n",
    "                    if idxnew.size!=0:\n",
    "                        clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[idxnew,:])\n",
    "                        print('new tx found', frameNumber)\n",
    "                        potentialTxs.loc[potentialTxs['frame']==frameNumber,['z', 'y', 'x', 'mrna']] = clsFrm[frameNumber][0][0:4]\n",
    "                        lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "                    if idxnew.size==0:\n",
    "                         if probTx[frameNumber]>0.7:\n",
    "                            idxnew2 = np.where(np.sum(np.abs(clsFrmSrtd[:,1:3]-particleCoordinates), axis=1)<=100)[0]\n",
    "\n",
    "                            clsFrm[frameNumber] = mergeTxSites(clsFrmSrtd[idxnew2,:])\n",
    "                            print('new tx added regardless since high prob', frameNumber)\n",
    "                            potentialTxs.loc[potentialTxs['frame']==frameNumber,['z', 'y', 'x', 'mrna']] = clsFrm[frameNumber][0][0:4]\n",
    "                            lastLocation = np.array(potentialTxs.loc[potentialTxs['frame']==frameNumber,['y', 'x']])\n",
    "    return potentialTxs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5957692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifyFinalTrackDataFrame(potentialTxs, potentialTxsFinal,total_number_of_tx_site):\n",
    "    #--------------------------------- Make dataframe\n",
    "    if np.size(potentialTxsFinal)==0:\n",
    "        if 'cluster_id' not in potentialTxs.columns:\n",
    "            potentialTxs['cluster_id']=0\n",
    "        potentialTxsFinal = deepcopy(potentialTxs)    \n",
    "    elif len(np.unique(potentialTxsFinal.cluster_id)) < total_number_of_tx_site:\n",
    "        new_cluster_id = np.unique(potentialTxsFinal['cluster_id'])[-1]+1\n",
    "        potentialTxs['cluster_id']=new_cluster_id\n",
    "        potentialTxsFinal = pd.concat([potentialTxsFinal, potentialTxs])\n",
    "    elif len(np.unique(potentialTxsFinal.cluster_id)) == total_number_of_tx_site:\n",
    "        chngid = int(input('Enter track to replace : '))\n",
    "        potentialTxs['cluster_id']=chngid\n",
    "        potentialTxsFinal.loc[potentialTxsFinal['cluster_id']==chngid]=potentialTxs\n",
    "    return potentialTxs, potentialTxsFinal\n",
    "\n",
    "def findMissingTranscriptionSitesFromTracks(potentialTxs, part1Test,spotsFrame,voxelRadius, objectRadius,selectedThreshold, sequenceCell, reference_spot,cellNumber,Tx_mask_new, BETA, gM,nP):\n",
    "    #---------------------- Find missing Txs\n",
    "    missingTXFrames = []\n",
    "    for frameNumber in range(len(potentialTxs)):  \n",
    "        t = part1Test.frame.values[np.argmin(abs(part1Test.frame.values-frameNumber))]\n",
    "        if np.abs(t-frameNumber)<=5:        \n",
    "            particleCoordinates = np.asarray(part1Test[part1Test['frame']==t])[0][:2]\n",
    "            if potentialTxs.iloc[frameNumber,2:4].sum()!=0:           \n",
    "                if np.sum(np.power(potentialTxs.iloc[frameNumber,2:4]-particleCoordinates,2))>25:\n",
    "                    brightest = spotsFrame[frameNumber][np.argsort(findSpotBrightness(spotsFrame[frameNumber][:,:], sequenceCell[frameNumber]))[-1]]\n",
    "                    if np.sum(np.abs(brightest-clsFrm[frameNumber][:,0:3]))>3:\n",
    "                        print('error in frame ', frameNumber, t)\n",
    "\n",
    "            elif potentialTxs.iloc[frameNumber,2:4].sum()==0:\n",
    "                if probTx[frameNumber]>0.6:\n",
    "                    if spotsFrame[frameNumber].size!=0:                \n",
    "                        brightest = spotsFrame[frameNumber][np.argsort(findSpotBrightness2D(spotsFrame[frameNumber][:,1:], mipSequenceCell[frameNumber]))[-1]]\n",
    "                        if clsFrm[frameNumber-1][:,0:3].size!=0:\n",
    "                            if np.sum(np.abs(brightest-clsFrm[frameNumber-1][:,0:3]))<4:\n",
    "                                print('missing Tx at :', frameNumber)\n",
    "                                missingTXFrames.append(frameNumber)\n",
    "                        elif clsFrm[frameNumber+1][:,0:3].size!=0:\n",
    "                            if np.sum(np.abs(brightest-clsFrm[frameNumber+1][:,0:3]))<4:\n",
    "                                print('missing Tx at :', frameNumber)\n",
    "                                missingTXFrames.append(frameNumber)\n",
    "    \n",
    "    print('Found possible missing transcription sites: ', len(missingTXFrames))\n",
    "\n",
    "    for ff in missingTXFrames:\n",
    "        print(ff)\n",
    "        lst = np.array(potentialTxs[potentialTxs['frame']==ff-1])[:,1:4]\n",
    "        if np.sum(lst)!=0:\n",
    "            lastLocation = lst\n",
    "        else:\n",
    "            lastLocation = np.array(potentialTxs[potentialTxs['frame']==ff+1])[:,1:4]\n",
    "        newtxs = findMissingTxSite(selectedThreshold, sequenceCell, reference_spot,cellNumber, Tx_mask_new, ff, lastLocation, bETA=BETA, gAMA=gM, numCs=nP, vR=voxelRadius, oR=objectRadius,reorderyn = False)\n",
    "        if newtxs.size!=0:\n",
    "            potentialTxs.loc[potentialTxs['frame']==ff,['z', 'y', 'x', 'mrna']] = newtxs[:,:4]\n",
    "    return potentialTxs\n",
    "\n",
    "def plotCoordinatesFound(potentialTxs, particle, plotFileName):\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    idxs=potentialTxs.loc[:,['y', 'x']].sum(axis=1)!=0\n",
    "    if sum(idxs)!=0:        \n",
    "        plt.scatter(potentialTxs.loc[idxs,'frame']-5, np.sum(potentialTxs.loc[idxs,['y', 'x']], axis=1), color='black', label='coordinates found')\n",
    "        plt.ylim([50,np.max(np.sum(potentialTxs.loc[idxs,['y', 'x']], axis=1))*1.2])\n",
    "    plt.scatter(particle['frame'], np.sum(particle.loc[:,['y', 'x']], axis=1), label='coordinates from HCT')\n",
    "    plt.legend(loc=0)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(potentialTxs['frame'], potentialTxs['mrna'])\n",
    "    plt.savefig(plotFileName)\n",
    "    \n",
    "def cleanClusters(clsFrm,Tx_mask_new):\n",
    "    for i in range(len(clsFrm)):\n",
    "        if clsFrm[i].size!=0:  \n",
    "            mask_in_frames = Tx_mask_new[clsFrm[i][:,1], clsFrm[i][:,2]]\n",
    "            clsFrm[i] = clsFrm[i][mask_in_frames]\n",
    "\n",
    "    if len(clsFrm[findFitstTxFrame(clsFrm)])>= 2:\n",
    "        print('choose spot!')\n",
    "        brightestSpot = clsFrm[findFitstTxFrame(clsFrm)][np.argmax(findSpotBrightness(clsFrm[findFitstTxFrame(clsFrm)], sequenceCell[findFitstTxFrame(clsFrm)]))]\n",
    "        clsFrm[findFitstTxFrame(clsFrm)] = brightestSpot.reshape(1,5)\n",
    "        print(brightestSpot)\n",
    "    return clsFrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c60d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTableAndCoordinates(potentialTxsFinal):\n",
    "    columnsid=['frame']\n",
    "    for clidu in np.unique(potentialTxsFinal.cluster_id):\n",
    "        if clidu ==0:\n",
    "            Tx1 = potentialTxsFinal[potentialTxsFinal['cluster_id']==0]\n",
    "            tableToDisplay = pd.DataFrame(Tx1.loc[:,['frame', 'mrna']].astype(int))\n",
    "            columnsid.append('mrna_'+str(clidu))\n",
    "        else:\n",
    "            Tx2 = potentialTxsFinal[potentialTxsFinal['cluster_id']==clidu]\n",
    "            tableToDisplay = pd.concat([tableToDisplay , Tx2.loc[:,['mrna']].astype(int)], axis=1)\n",
    "            columnsid.append('mrna_'+str(clidu))\n",
    "    tableToDisplay.columns = columnsid\n",
    "    potentialTxsFinal.to_pickle(pathToResults+'/'+cellNumber+'_mrna_coordinates.pkl')\n",
    "    tableToDisplay.to_csv(pathToResults+'/'+cellNumber+'_mrna.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9023a7c",
   "metadata": {},
   "source": [
    "## Select home folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98ed857",
   "metadata": {},
   "outputs": [],
   "source": [
    "midentifier = 'cell_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad145ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen home folder: C:/Users/uid-1204/Desktop/bigFIS_trial_data_june2025/Hela_h9_h2_o1p1_mcp_td_SG_1hrbasal_14hr_10ng_TNF_75ms_5%_2_F00\n"
     ]
    }
   ],
   "source": [
    "baseFolder = choose_home_folder() \n",
    "thresholdFile = pd.read_csv(baseFolder+'/thresholds.csv', index_col=0)\n",
    "\n",
    "\n",
    "print(\"Chosen home folder:\", baseFolder) # folder containg folder of movies\n",
    "sessionNames = [os.path.join(baseFolder+'/'+i) for i in os.listdir(baseFolder) if midentifier in i and os.path.isdir(os.path.join(baseFolder,i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b333cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToResults= baseFolder+'/results_new_new/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b87d6",
   "metadata": {},
   "source": [
    "## Enter the alpha chosen in the last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e9369c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the alpha chosen in the last step :0.6\n"
     ]
    }
   ],
   "source": [
    "al = input('Enter the alpha chosen in the last step :')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b572992",
   "metadata": {},
   "source": [
    "## Choose the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddbb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the root window\n",
    "root = Tk()\n",
    "root.geometry('180x200')\n",
    " \n",
    "# Create a listbox\n",
    "listbox = Listbox(root, width=90, height=100, selectmode=SINGLE)\n",
    " \n",
    "# Inserting the listbox items\n",
    "for i in range(len(sessionNames)):\n",
    "    listbox.insert(i+1, sessionNames[i].split('/')[-1])\n",
    "\n",
    "# Function for printing the\n",
    "# selected listbox value(s)\n",
    "def selected_item():\n",
    "    global chosenCell\n",
    "    # Traverse the tuple returned by\n",
    "    # curselection method and print\n",
    "    # corresponding value(s) in the listbox\n",
    "    chosenCell = listbox.get(listbox.curselection())\n",
    "    root.destroy()\n",
    "    \n",
    "# Create a button widget and\n",
    "# map the command parameter to\n",
    "# selected_item function\n",
    "btn = Button(root, text='Choose', command=selected_item)\n",
    " \n",
    "# Placing the button and listbox\n",
    "btn.pack(side='bottom')\n",
    "listbox.pack()\n",
    " \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74aefd",
   "metadata": {},
   "source": [
    "## Specify Input and Output folders, identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411d36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellNumber,  cell_17\n",
      "cellNumber =  cell_17\n"
     ]
    }
   ],
   "source": [
    "cellNumber = chosenCell\n",
    "print('cellNumber, ', cellNumber)\n",
    "\n",
    "trackFilePath = os.path.join(baseFolder,cellNumber)\n",
    "trackFilesToAnalyse = [os.path.join(trackFilePath,i) for i in os.listdir(trackFilePath) if 'mrnaTracks' in i]\n",
    "if len(trackFilesToAnalyse)!=0:\n",
    "    trackPath = Path(trackFilesToAnalyse[0])\n",
    "\n",
    "    trackFile = trackPath.name\n",
    "    cellFolderPath = trackPath.parents[0]\n",
    "\n",
    "\n",
    "    thresholdFile = pd.read_csv(cellFolderPath.parent.joinpath('thresholds.csv'), index_col=0)\n",
    "    extension = '.tif'\n",
    "    print('cellNumber = ', cellNumber)\n",
    "    idx = np.where(thresholdFile['cell'] == cellNumber)[0][0]\n",
    "\n",
    "    thresholdSelected = thresholdFile['threshold'][idx]\n",
    "    sequenceCell = imr(str(cellFolderPath.joinpath('*.tif')))\n",
    "    mipSequenceCell = np.max(sequenceCell, axis=1)\n",
    "    MaxTimePoint = sequenceCell.shape[0]\n",
    "    spcl = np.load(cellFolderPath.joinpath(str(cellNumber)+'_spots_and_clusters_27_May'+al+'.npz'),allow_pickle=True)\n",
    "    reference_spot = spcl['reference_spot']\n",
    "    spotsFrame = spcl['spotsFrame']\n",
    "    newClusterFile = np.load(os.path.join(pathToResults,(str(cellNumber)+'newClusters.npz')), allow_pickle=True)\n",
    "    newClusterFrame = newClusterFile['newClusterFrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b519cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "potentialTxsFinal = pd.read_pickle(os.path.join(pathToResults,cellNumber+'_finalDataframe.pkl'))\n",
    "dftracksFinal = columnHd, newClusterFrame, tableToDisplay, dftracksFinal = makeTrackData(potentialTxsFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd114b32",
   "metadata": {},
   "source": [
    "## Display Results ( Run after analysing all Transcription sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e71217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari._qt.widgets.qt_viewer_dock_widget.QtViewerDockWidget at 0x2000f5bbc10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 \n",
      " [  1 104  66]\n",
      "done!\n",
      "new tx found [[  1. 104.  66.   2.   0.]]\n",
      "new value saved\n",
      "new value saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cell_label_clean_file = cellFolderPath.parent.joinpath('masks_tx/blur_'+cellNumber+'.npy')\n",
    "cell_label_clean = np.load(cell_label_clean_file)\n",
    "def getDetectedPointsForFrame(pts_coordinates, frameNumer):\n",
    "    sd = np.shape(pts_coordinates[frameNumer][:])\n",
    "    pts_coords = np.empty([sd[0],sd[1]-1])\n",
    "    for ii in range(np.shape(pts_coordinates[frameNumer][:])[0]):\n",
    "        pts_coords[ii,:] = pts_coordinates[frameNumer][ii][1:]\n",
    "    return pts_coords\n",
    "\n",
    "def getDetectedClustersForFrame(pts_coordinates, frameNumer):\n",
    "    sd = np.shape(pts_coordinates[frameNumer][:])\n",
    "    pts_coords = np.empty([sd[0],sd[1]-3])\n",
    "    for ii in range(np.shape(pts_coordinates[frameNumer][:])[0]):\n",
    "        pts_coords[ii,:] = pts_coordinates[frameNumer][ii][1:3]\n",
    "    return pts_coords\n",
    "\n",
    "def set_pts_features(pts_layer, cls_layer, pts_coordinates, cluster_coordinate, image_layer_ndim, step): #TxLayer\n",
    "    # step is a 4D coordinate with the current slider position for each dim\n",
    "    frameNumber = step[0]  # grab the leading (\"time\") coordinate\n",
    "    if image_layer_ndim==4:\n",
    "        pts_layer.data = pts_coordinates[frameNumber]\n",
    "        cls_layer.data = cluster_coordinate[frameNumber][:,:3]\n",
    "    else:\n",
    "        pts_layer.data = getDetectedPointsForFrame(pts_coordinates,frameNumber)\n",
    "        cls_layer.data = getDetectedClustersForFrame(cluster_coordinate,frameNumber)\n",
    "\n",
    "\n",
    "selectedThreshold = int(thresholdSelected)\n",
    "pts_coordinates = spotsFrame\n",
    "cluster_coordinate = newClusterFrame\n",
    "viewer = napari.Viewer()\n",
    "image_layer = viewer.add_image(\n",
    "        mipSequenceCell, colormap='green' #maxImageCell\n",
    "        )\n",
    "if image_layer.data.ndim == 4:\n",
    "    bigfish_Spots = viewer.add_points(\n",
    "            spotsFrame[int(image_layer.data.shape[0]/2-1)],\n",
    "            face_color='#00000000',\n",
    "            size=4,\n",
    "            edge_width=0.3,\n",
    "            edge_width_is_relative=False,\n",
    "            edge_color='white',\n",
    "            name = 'bigFish Detected Spots'\n",
    "            )\n",
    "    bigfish_clusters = viewer.add_points(\n",
    "        cluster_coordinate[int(image_layer.data.shape[0]/2-1)][:,:3],\n",
    "        face_color='#00000000',\n",
    "        size=8,\n",
    "        edge_width=0.3,\n",
    "        edge_width_is_relative=False,\n",
    "        edge_color='red',\n",
    "        symbol='diamond',\n",
    "        name = 'bigFish Clusters'\n",
    "        )\n",
    "\n",
    "elif image_layer.data.ndim == 3:\n",
    "    bigfish_Spots = viewer.add_points(\n",
    "            getDetectedPointsForFrame(pts_coordinates,int(image_layer.data.shape[0]/2-1)),\n",
    "            face_color='#00000000',\n",
    "            size=4,\n",
    "            edge_width=0.3,\n",
    "            edge_width_is_relative=False,\n",
    "            edge_color='white',\n",
    "            name = 'bigFish Detected Spots'\n",
    "            )\n",
    "    bigfish_clusters = viewer.add_points(\n",
    "        getDetectedClustersForFrame(cluster_coordinate,int(image_layer.data.shape[0]/2-1)),\n",
    "        face_color='#00000000',\n",
    "        size=8,\n",
    "        edge_width=0.3,\n",
    "        edge_width_is_relative=False,\n",
    "        edge_color='red',\n",
    "        symbol='diamond',\n",
    "        name = 'bigFish Clusters'\n",
    "        )\n",
    "\n",
    "bigfish_tracks = viewer.add_tracks(dftracksFinal, \n",
    "                                   name='TS tracks')\n",
    "\n",
    "viewer.dims.events.current_step.connect(\n",
    "        lambda event: set_pts_features(bigfish_Spots, bigfish_clusters, pts_coordinates, cluster_coordinate,image_layer.data.ndim, event.value)\n",
    "        )\n",
    "\n",
    "@magicgui(call_button='Add Transcription site',main_window=False,\n",
    "          saveTableButton=dict(widget_type=\"PushButton\", text=\"Save mrna data\"),\n",
    "          loadMaskBtn=dict(widget_type=\"PushButton\", text=\"Load Mask\")\n",
    "         )\n",
    "def onAddTranscriptionSite(saveTableButton=True,\n",
    "                           add_to_id=1,\n",
    "                           cluster_threshold=1,\n",
    "                           cluster_Gamma=4,\n",
    "                          loadMaskBtn=True):\n",
    "    print(viewer.dims.current_step[0],'\\n',spotsFrame[viewer.dims.current_step[0]][list(viewer.layers[1].selected_data)[0]])\n",
    "    newtxs = findMissingTxSite(selectedThreshold, sequenceCell, reference_spot, cellNumber, label(cell_label_clean).astype(bool), viewer.dims.current_step[0], spotsFrame[viewer.dims.current_step[0]][list(viewer.layers[1].selected_data)[0]], cluster_threshold, cluster_Gamma, 1, 600, (600,121,121), (600,150,150), False)\n",
    "    if newtxs.size!=0:\n",
    "        print('new tx found', newtxs)\n",
    "        potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==add_to_id,potentialTxsFinal['frame']==viewer.dims.current_step[0]),['z','y','x','mrna']]=newtxs[:,:-1]\n",
    "        columnHd, newClusterFrame, tableToDisplay, dftracksFinal = makeTrackData(potentialTxsFinal)\n",
    "        indexToAdd = np.where(np.logical_and(potentialTxsFinal['frame']==viewer.dims.current_step[0], potentialTxsFinal['cluster_id']==add_to_id))[0]\n",
    "        \n",
    "        save_val = {'data': newtxs[0][3], 'row': viewer.dims.current_step[0], 'column': add_to_id+1, 'column_header': columnHd[add_to_id], 'row_header': str(viewer.dims.current_step[0])}\n",
    "        table.data[viewer.dims.current_step[0], add_to_id+1]=newtxs[0][3]\n",
    "        catchval(save_val)\n",
    "        newtxs[:,4] = add_to_id\n",
    "        potentialTxsFinal.to_pickle(pathToResults+'/'+cellNumber+'_mrna_coordinates.pkl') \n",
    "        \n",
    "@onAddTranscriptionSite.saveTableButton.clicked.connect\n",
    "def catchval(new_value):\n",
    "    if new_value==False:\n",
    "        table.to_dataframe().to_csv(baseFolder+'/'+cellNumber+'/'+cellNumber+'_mrna.csv')\n",
    "    else:  \n",
    "        print('new value saved')\n",
    "        mrnaTable[new_value['column_header']][new_value['row_header']] = new_value['data']\n",
    "        table.to_dataframe().to_csv(pathToResults+'/'+cellNumber+'_mrna.csv')\n",
    "        \n",
    "\n",
    "@onAddTranscriptionSite.loadMaskBtn.clicked.connect\n",
    "def onLoadMask():\n",
    "    print('maskloaded')\n",
    "    viewer.add_image(label(cell_label_clean))\n",
    "    \n",
    "tablePath = pathToResults+'/'+cellNumber+'_mrna.csv'\n",
    "if os.path.exists(tablePath):\n",
    "    dft = pd.read_csv(tablePath, index_col=0)\n",
    "    mrnaTable = dft.astype(int).to_dict()\n",
    "else:\n",
    "    mrnaTable = tableToDisplay.astype(int).to_dict()\n",
    "tableToDisplay.to_csv(pathToResults+'/'+cellNumber+'_mrna.csv')\n",
    "potentialTxsFinal.to_pickle(pathToResults+'/'+cellNumber+'_mrna_coordinates.pkl')\n",
    "\n",
    "table = Table(value=mrnaTable)\n",
    "table.changed.connect(catchval)\n",
    "tablewidget = viewer.window.add_dock_widget(table, tabify=False, name = 'mrna table')\n",
    "viewer.window.add_dock_widget(onAddTranscriptionSite, name = 'mrna table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e04d6838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>frame</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>20.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "      <td>28.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1</td>\n",
       "      <td>630</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>27.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster_id  frame     y     x\n",
       "359           0    359  20.0  49.0\n",
       "360           0    360  21.0  49.0\n",
       "361           0    361  20.0  48.0\n",
       "362           0    362  20.0  46.0\n",
       "363           0    363  21.0  48.0\n",
       "364           0    364  22.0  49.0\n",
       "365           0    365  21.0  50.0\n",
       "629           1    629  28.0  67.0\n",
       "630           1    630  28.0  68.0\n",
       "631           1    631  28.0  68.0\n",
       "632           1    632  27.0  68.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftracksFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d59636",
   "metadata": {},
   "outputs": [],
   "source": [
    "txid=1\n",
    "meanxCoordinate = np.mean(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['x']!=0) ,'x'].values)\n",
    "sdxCoordinate = np.std(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['x']!=0) ,'x'].values)\n",
    "\n",
    "meanyCoordinate = np.mean(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['y']!=0) ,'y'].values)\n",
    "sdyCoordinate = np.std(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['y']!=0) ,'y'].values)\n",
    "\n",
    "meanzCoordinate = np.mean(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['z']!=0) ,'z'].values)\n",
    "sdzCoordinate = np.std(potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['z']!=0) ,'z'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0775cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanCoordinates = [meanzCoordinate, meanyCoordinate, meanxCoordinate]\n",
    "sdCoordinates = [sdzCoordinate, sdyCoordinate, sdxCoordinate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d62640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "limitsz = [np.round(meanzCoordinate-1.5*sdzCoordinate), np.round(meanzCoordinate+1.5*sdzCoordinate)]\n",
    "limitsy = [np.round(meanyCoordinate-1.5*sdyCoordinate), np.round(meanyCoordinate+1.5*sdyCoordinate)]\n",
    "limitsx = [np.round(meanxCoordinate-1.5*sdxCoordinate), np.round(meanxCoordinate+1.5*sdxCoordinate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a30c7f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125.0, 132.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limitsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c8a7501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[145.0, 152.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limitsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b797e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 4.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limitsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63e11bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c7d4056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 148 = [[  5 130 150]] diff = [5.]\n",
      "frame 203 = [[  3 131 148]] diff = [4.]\n",
      "frame 204 = [[  3 132 147]] diff = [6.]\n",
      "frame 205 = [[  3 132 149]] diff = [4.]\n",
      "frame 206 = [[  3 134 146]] diff = [9.]\n",
      "frame 207 = [[  3 131 148]] diff = [4.]\n",
      "frame 208 = [[  3 132 148]] diff = [5.]\n",
      "frame 209 = [[  3 132 149]] diff = [4.]\n",
      "frame 211 = [[  3 130 149]] diff = [2.]\n",
      "frame 212 = [[  2 130 148]] diff = [3.]\n",
      "frame 213 = [[  5 132 152]] diff = [9.]\n",
      "frame 227 = [[  8 132 148]] diff = [10.]\n",
      "frame 251 = [[  3 129 150]] diff = [2.]\n",
      "frame 252 = [[  3 132 150]] diff = [5.]\n",
      "frame 253 = [[  3 128 149]] diff = [1.]\n",
      "frame 254 = [[  3 132 149]] diff = [4.]\n",
      "frame 255 = [[  3 132 150]] diff = [5.]\n",
      "frame 256 = [[  3 130 151]] diff = [4.]\n",
      "frame 257 = [[  3 131 151]] diff = [5.]\n",
      "frame 258 = [[  3 131 152]] diff = [6.]\n",
      "frame 259 = [[  2 131 144]\n",
      " [  3 133 150]] diff = [8. 6.]\n",
      "frame 260 = [[  3 132 150]] diff = [5.]\n",
      "frame 261 = [[  3 132 150]] diff = [5.]\n",
      "frame 262 = [[  3 129 150]] diff = [2.]\n",
      "frame 263 = [[  3 131 151]] diff = [5.]\n",
      "frame 264 = [[  3 130 148]] diff = [3.]\n",
      "frame 265 = [[  3 130 149]] diff = [2.]\n",
      "frame 266 = [[  3 128 150]] diff = [2.]\n",
      "frame 267 = [[  3 129 149]] diff = [1.]\n",
      "frame 268 = [[  3 130 149]] diff = [2.]\n",
      "frame 269 = [[  3 129 150]] diff = [2.]\n",
      "frame 270 = [[  3 128 150]] diff = [2.]\n",
      "frame 271 = [[  3 128 150]] diff = [2.]\n",
      "frame 272 = [[  3 127 152]] diff = [5.]\n",
      "frame 273 = [[  3 130 151]] diff = [4.]\n",
      "frame 274 = [[  3 128 150]] diff = [2.]\n",
      "frame 275 = [[  3 129 150]\n",
      " [  4 130 153]] diff = [2. 7.]\n",
      "frame 276 = [[  3 129 149]] diff = [1.]\n",
      "frame 277 = [[  3 130 149]] diff = [2.]\n",
      "frame 278 = [[  3 129 149]] diff = [1.]\n",
      "frame 279 = [[  3 130 148]] diff = [3.]\n",
      "frame 280 = [[  3 130 149]] diff = [2.]\n",
      "frame 281 = [[  4 130 148]] diff = [4.]\n",
      "frame 283 = [[  7 130 150]] diff = [7.]\n",
      "frame 300 = [[  7 126 147]] diff = [9.]\n",
      "frame 338 = [[  2 129 148]] diff = [2.]\n",
      "frame 339 = [[  3 129 147]] diff = [3.]\n",
      "frame 340 = [[  3 128 149]] diff = [1.]\n",
      "frame 341 = [[  3 129 148]] diff = [2.]\n",
      "frame 342 = [[  2 129 146]] diff = [4.]\n",
      "frame 343 = [[  2 131 146]] diff = [6.]\n",
      "frame 344 = [[  2 131 144]] diff = [8.]\n",
      "frame 345 = [[  2 131 146]] diff = [6.]\n",
      "frame 346 = [[  2 129 146]] diff = [4.]\n",
      "frame 347 = [[  2 130 146]] diff = [5.]\n",
      "frame 348 = [[  2 131 146]] diff = [6.]\n",
      "frame 349 = [[  2 129 146]] diff = [4.]\n",
      "frame 350 = [[  2 130 147]] diff = [4.]\n",
      "frame 351 = [[  2 130 148]] diff = [3.]\n",
      "frame 352 = [[  2 129 147]] diff = [3.]\n",
      "frame 353 = [[  2 128 146]] diff = [4.]\n",
      "frame 354 = [[  2 130 148]] diff = [3.]\n",
      "frame 355 = [[  2 128 146]] diff = [4.]\n",
      "frame 356 = [[  2 130 148]] diff = [3.]\n",
      "frame 357 = [[  2 131 147]] diff = [5.]\n",
      "frame 358 = [[  2 127 148]] diff = [3.]\n",
      "frame 359 = [[  2 130 149]] diff = [2.]\n",
      "frame 360 = [[  2 128 149]] diff = [1.]\n",
      "frame 361 = [[  2 130 148]] diff = [3.]\n",
      "frame 362 = [[  2 129 147]] diff = [3.]\n",
      "frame 363 = [[  3 129 148]] diff = [2.]\n",
      "frame 364 = [[  2 127 150]] diff = [3.]\n",
      "frame 365 = [[  2 127 148]] diff = [3.]\n",
      "frame 366 = [[  2 127 148]] diff = [3.]\n",
      "frame 367 = [[  2 128 149]] diff = [1.]\n",
      "frame 368 = [[  2 128 149]] diff = [1.]\n",
      "frame 369 = [[  2 127 149]] diff = [2.]\n",
      "frame 370 = [[  3 128 148]\n",
      " [  6 129 150]] diff = [2. 5.]\n",
      "frame 371 = [[  2 128 150]] diff = [2.]\n",
      "frame 372 = [[  2 128 149]] diff = [1.]\n",
      "frame 373 = [[  2 128 150]] diff = [2.]\n",
      "frame 374 = [[  2 130 150]] diff = [3.]\n",
      "frame 375 = [[  2 129 150]] diff = [2.]\n",
      "frame 376 = [[  2 122 147]\n",
      " [  2 131 150]] diff = [9. 4.]\n",
      "frame 377 = [[  2 129 149]\n",
      " [  3 129 143]] diff = [1. 7.]\n",
      "frame 378 = [[  2 126 149]] diff = [3.]\n",
      "frame 379 = [[  2 128 150]] diff = [2.]\n",
      "frame 380 = [[  2 126 151]\n",
      " [  7 131 151]] diff = [5. 9.]\n",
      "frame 381 = [[  3 126 152]] diff = [6.]\n",
      "frame 382 = [[  2 126 151]\n",
      " [  7 129 152]] diff = [5. 8.]\n",
      "frame 383 = [[  2 126 150]] diff = [4.]\n",
      "frame 384 = [[  2 127 151]] diff = [4.]\n",
      "frame 385 = [[  2 127 150]] diff = [3.]\n",
      "frame 386 = [[  2 126 151]] diff = [5.]\n",
      "frame 387 = [[  2 126 150]] diff = [4.]\n",
      "frame 388 = [[  2 127 151]] diff = [4.]\n",
      "frame 389 = [[  2 125 149]] diff = [4.]\n",
      "frame 390 = [[  2 127 149]] diff = [2.]\n",
      "frame 391 = [[  2 126 149]] diff = [3.]\n",
      "frame 392 = [[  2 125 149]] diff = [4.]\n",
      "frame 393 = [[  2 126 149]] diff = [3.]\n",
      "frame 394 = [[  3 126 148]] diff = [4.]\n",
      "frame 395 = [[  2 125 150]] diff = [5.]\n",
      "frame 396 = [[  2 125 150]] diff = [5.]\n",
      "frame 397 = [[  3 126 152]\n",
      " [  4 132 152]] diff = [6. 8.]\n",
      "frame 398 = [[  3 127 153]] diff = [6.]\n",
      "frame 399 = [[  2 127 150]] diff = [3.]\n",
      "frame 400 = [[  2 127 151]\n",
      " [  6 127 145]] diff = [4. 9.]\n",
      "frame 401 = [[  2 128 152]] diff = [4.]\n",
      "frame 402 = [[  2 129 152]] diff = [4.]\n",
      "frame 403 = [[  2 126 152]] diff = [6.]\n",
      "frame 404 = [[  5 129 143]] diff = [9.]\n",
      "frame 422 = [[  4 122 148]] diff = [9.]\n",
      "frame 424 = [[  3 121 147]] diff = [10.]\n",
      "frame 426 = [[  4 128 147]] diff = [4.]\n",
      "frame 461 = [[  7 129 149]] diff = [5.]\n",
      "frame 480 = [[  7 126 149]] diff = [7.]\n",
      "frame 534 = [[  3 131 150]] diff = [4.]\n",
      "frame 535 = [[  4 130 148]] diff = [4.]\n",
      "frame 795 = [[  4 121 148]] diff = [10.]\n",
      "frame 796 = [[  4 121 149]] diff = [9.]\n",
      "frame 797 = [[  4 121 149]] diff = [9.]\n",
      "frame 800 = [[  4 120 149]] diff = [10.]\n",
      "frame 802 = [[  4 121 148]] diff = [10.]\n",
      "frame 803 = [[  4 121 149]] diff = [9.]\n",
      "frame 806 = [[  4 121 148]] diff = [10.]\n",
      "frame 808 = [[  4 121 149]] diff = [9.]\n",
      "frame 810 = [[  5 129 145]] diff = [7.]\n",
      "frame 811 = [[  5 128 146]] diff = [6.]\n"
     ]
    }
   ],
   "source": [
    "emptyFrames =[]\n",
    "potentialSpots =[]\n",
    "for i in range(MaxTimePoint):\n",
    "    idxs = np.where(np.round(np.sum(np.abs(spotsFrame[i][:,0:] - meanCoordinates), axis=1))<=10)[0]\n",
    "    if idxs.size!=0:\n",
    "        emptyFrames.append(i)\n",
    "        potentialSpots.append([i,spotsFrame[i][idxs,:]])\n",
    "        print('frame '+str(i)+' = '+ str(spotsFrame[i][idxs[:],:])+' diff = '+ str(np.round(np.sum(np.abs(spotsFrame[i][idxs,0:] - meanCoordinates), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08eb37e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[148, array([[  5, 130, 150]])],\n",
       " [203, array([[  3, 131, 148]])],\n",
       " [204, array([[  3, 132, 147]])],\n",
       " [205, array([[  3, 132, 149]])],\n",
       " [206, array([[  3, 134, 146]])],\n",
       " [207, array([[  3, 131, 148]])],\n",
       " [208, array([[  3, 132, 148]])],\n",
       " [209, array([[  3, 132, 149]])],\n",
       " [211, array([[  3, 130, 149]])],\n",
       " [212, array([[  2, 130, 148]])],\n",
       " [213, array([[  5, 132, 152]])],\n",
       " [227, array([[  8, 132, 148]])],\n",
       " [251, array([[  3, 129, 150]])],\n",
       " [252, array([[  3, 132, 150]])],\n",
       " [253, array([[  3, 128, 149]])],\n",
       " [254, array([[  3, 132, 149]])],\n",
       " [255, array([[  3, 132, 150]])],\n",
       " [256, array([[  3, 130, 151]])],\n",
       " [257, array([[  3, 131, 151]])],\n",
       " [258, array([[  3, 131, 152]])],\n",
       " [259,\n",
       "  array([[  2, 131, 144],\n",
       "         [  3, 133, 150]])],\n",
       " [260, array([[  3, 132, 150]])],\n",
       " [261, array([[  3, 132, 150]])],\n",
       " [262, array([[  3, 129, 150]])],\n",
       " [263, array([[  3, 131, 151]])],\n",
       " [264, array([[  3, 130, 148]])],\n",
       " [265, array([[  3, 130, 149]])],\n",
       " [266, array([[  3, 128, 150]])],\n",
       " [267, array([[  3, 129, 149]])],\n",
       " [268, array([[  3, 130, 149]])],\n",
       " [269, array([[  3, 129, 150]])],\n",
       " [270, array([[  3, 128, 150]])],\n",
       " [271, array([[  3, 128, 150]])],\n",
       " [272, array([[  3, 127, 152]])],\n",
       " [273, array([[  3, 130, 151]])],\n",
       " [274, array([[  3, 128, 150]])],\n",
       " [275,\n",
       "  array([[  3, 129, 150],\n",
       "         [  4, 130, 153]])],\n",
       " [276, array([[  3, 129, 149]])],\n",
       " [277, array([[  3, 130, 149]])],\n",
       " [278, array([[  3, 129, 149]])],\n",
       " [279, array([[  3, 130, 148]])],\n",
       " [280, array([[  3, 130, 149]])],\n",
       " [281, array([[  4, 130, 148]])],\n",
       " [283, array([[  7, 130, 150]])],\n",
       " [300, array([[  7, 126, 147]])],\n",
       " [338, array([[  2, 129, 148]])],\n",
       " [339, array([[  3, 129, 147]])],\n",
       " [340, array([[  3, 128, 149]])],\n",
       " [341, array([[  3, 129, 148]])],\n",
       " [342, array([[  2, 129, 146]])],\n",
       " [343, array([[  2, 131, 146]])],\n",
       " [344, array([[  2, 131, 144]])],\n",
       " [345, array([[  2, 131, 146]])],\n",
       " [346, array([[  2, 129, 146]])],\n",
       " [347, array([[  2, 130, 146]])],\n",
       " [348, array([[  2, 131, 146]])],\n",
       " [349, array([[  2, 129, 146]])],\n",
       " [350, array([[  2, 130, 147]])],\n",
       " [351, array([[  2, 130, 148]])],\n",
       " [352, array([[  2, 129, 147]])],\n",
       " [353, array([[  2, 128, 146]])],\n",
       " [354, array([[  2, 130, 148]])],\n",
       " [355, array([[  2, 128, 146]])],\n",
       " [356, array([[  2, 130, 148]])],\n",
       " [357, array([[  2, 131, 147]])],\n",
       " [358, array([[  2, 127, 148]])],\n",
       " [359, array([[  2, 130, 149]])],\n",
       " [360, array([[  2, 128, 149]])],\n",
       " [361, array([[  2, 130, 148]])],\n",
       " [362, array([[  2, 129, 147]])],\n",
       " [363, array([[  3, 129, 148]])],\n",
       " [364, array([[  2, 127, 150]])],\n",
       " [365, array([[  2, 127, 148]])],\n",
       " [366, array([[  2, 127, 148]])],\n",
       " [367, array([[  2, 128, 149]])],\n",
       " [368, array([[  2, 128, 149]])],\n",
       " [369, array([[  2, 127, 149]])],\n",
       " [370,\n",
       "  array([[  3, 128, 148],\n",
       "         [  6, 129, 150]])],\n",
       " [371, array([[  2, 128, 150]])],\n",
       " [372, array([[  2, 128, 149]])],\n",
       " [373, array([[  2, 128, 150]])],\n",
       " [374, array([[  2, 130, 150]])],\n",
       " [375, array([[  2, 129, 150]])],\n",
       " [376,\n",
       "  array([[  2, 122, 147],\n",
       "         [  2, 131, 150]])],\n",
       " [377,\n",
       "  array([[  2, 129, 149],\n",
       "         [  3, 129, 143]])],\n",
       " [378, array([[  2, 126, 149]])],\n",
       " [379, array([[  2, 128, 150]])],\n",
       " [380,\n",
       "  array([[  2, 126, 151],\n",
       "         [  7, 131, 151]])],\n",
       " [381, array([[  3, 126, 152]])],\n",
       " [382,\n",
       "  array([[  2, 126, 151],\n",
       "         [  7, 129, 152]])],\n",
       " [383, array([[  2, 126, 150]])],\n",
       " [384, array([[  2, 127, 151]])],\n",
       " [385, array([[  2, 127, 150]])],\n",
       " [386, array([[  2, 126, 151]])],\n",
       " [387, array([[  2, 126, 150]])],\n",
       " [388, array([[  2, 127, 151]])],\n",
       " [389, array([[  2, 125, 149]])],\n",
       " [390, array([[  2, 127, 149]])],\n",
       " [391, array([[  2, 126, 149]])],\n",
       " [392, array([[  2, 125, 149]])],\n",
       " [393, array([[  2, 126, 149]])],\n",
       " [394, array([[  3, 126, 148]])],\n",
       " [395, array([[  2, 125, 150]])],\n",
       " [396, array([[  2, 125, 150]])],\n",
       " [397,\n",
       "  array([[  3, 126, 152],\n",
       "         [  4, 132, 152]])],\n",
       " [398, array([[  3, 127, 153]])],\n",
       " [399, array([[  2, 127, 150]])],\n",
       " [400,\n",
       "  array([[  2, 127, 151],\n",
       "         [  6, 127, 145]])],\n",
       " [401, array([[  2, 128, 152]])],\n",
       " [402, array([[  2, 129, 152]])],\n",
       " [403, array([[  2, 126, 152]])],\n",
       " [404, array([[  5, 129, 143]])],\n",
       " [422, array([[  4, 122, 148]])],\n",
       " [424, array([[  3, 121, 147]])],\n",
       " [426, array([[  4, 128, 147]])],\n",
       " [461, array([[  7, 129, 149]])],\n",
       " [480, array([[  7, 126, 149]])],\n",
       " [534, array([[  3, 131, 150]])],\n",
       " [535, array([[  4, 130, 148]])],\n",
       " [795, array([[  4, 121, 148]])],\n",
       " [796, array([[  4, 121, 149]])],\n",
       " [797, array([[  4, 121, 149]])],\n",
       " [800, array([[  4, 120, 149]])],\n",
       " [802, array([[  4, 121, 148]])],\n",
       " [803, array([[  4, 121, 149]])],\n",
       " [806, array([[  4, 121, 148]])],\n",
       " [808, array([[  4, 121, 149]])],\n",
       " [810, array([[  5, 129, 145]])],\n",
       " [811, array([[  5, 128, 146]])]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potentialSpots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dbdd790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "new tx found at frame 148 [[  5. 130. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 203 [[  3. 131. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 204 [[  3. 132. 147.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 205 [[  3. 132. 149.   1.   0.]]\n",
      "done!\n",
      "not found (not in mask)\n",
      "done!\n",
      "new tx found at frame 207 [[  3. 131. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 208 [[  3. 132. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 209 [[  3. 132. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 211 [[  3. 130. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 212 [[  2. 130. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 213 [[  5. 132. 151.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 227 [[  8. 132. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 251 [[  3. 129. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 252 [[  3. 132. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 253 [[  3. 128. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 254 [[  3. 131. 149.   3.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 256 [[  3. 130. 151.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 257 [[  3. 131. 150.   3.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "Choose spot for frame 259\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "not found (not close to last location)\n",
      "\n",
      "Enter 0 for spot []\n",
      "Enter 1 for spot []\n",
      "None0\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 261 [[  3. 132. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 262 [[  3. 129. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 263 [[  3. 131. 151.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 264 [[  3. 129. 148.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 265 [[  3. 130. 149.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 266 [[  3. 128. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 267 [[  3. 129. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 268 [[  3. 129. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 269 [[  3. 129. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 270 [[  3. 128. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 271 [[  3. 128. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 272 [[  3. 127. 152.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 273 [[  3. 130. 151.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 274 [[  3. 128. 150.   2.   0.]]\n",
      "Choose spot for frame 275\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  3. 129. 150.   1.   0.]]\n",
      "Enter 1 for spot [[  4. 130. 153.   1.   0.]]\n",
      "None0\n",
      "new tx found at frame 275 [[  3. 128. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 276 [[  3. 129. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 277 [[  3. 130. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 278 [[  3. 128. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 279 [[  3. 130. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 280 [[  3. 130. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 281 [[  4. 130. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 283 [[  7. 130. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 300 [[  7. 126. 147.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 338 [[  2. 129. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 339 [[  3. 129. 147.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 340 [[  3. 128. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 341 [[  3. 129. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 342 [[  2. 129. 146.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 343 [[  2. 131. 146.   1.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 345 [[  2. 131. 146.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 346 [[  2. 129. 146.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 347 [[  2. 130. 146.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 348 [[  2. 131. 146.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 349 [[  2. 129. 146.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 350 [[  2. 130. 147.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 351 [[  2. 129. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 352 [[  2. 129. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 353 [[  2. 128. 146.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 354 [[  2. 130. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 355 [[  2. 128. 145.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 356 [[  2. 130. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 357 [[  2. 130. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 358 [[  2. 127. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 359 [[  2. 130. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 360 [[  2. 128. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 361 [[  2. 130. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 362 [[  2. 129. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 363 [[  3. 129. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 364 [[  2. 127. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 365 [[  2. 127. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 366 [[  2. 126. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 367 [[  2. 128. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 368 [[  2. 128. 148.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 369 [[  2. 127. 148.   2.   0.]]\n",
      "Choose spot for frame 370\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  3. 128. 148.   2.   0.]]\n",
      "Enter 1 for spot [[  6. 129. 150.   2.   0.]]\n",
      "None0\n",
      "new tx found at frame 370 [[  2. 127. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 371 [[  2. 128. 149.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 372 [[  2. 127. 149.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 373 [[  2. 128. 149.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 374 [[  2. 130. 149.   4.   0.]]\n",
      "done!\n",
      "new tx found at frame 375 [[  2. 129. 149.   4.   0.]]\n",
      "Choose spot for frame 376\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  2. 122. 147.   3.   0.]]\n",
      "Enter 1 for spot [[  2. 130. 150.   4.   0.]]\n",
      "None1\n",
      "new tx found at frame 376 [[  2. 129. 149.   4.   0.]]\n",
      "Choose spot for frame 377\n",
      "done!\n",
      "done!\n",
      "not found (not close to last location)\n",
      "\n",
      "Enter 0 for spot [[  2. 129. 149.   4.   0.]]\n",
      "Enter 1 for spot []\n",
      "None0\n",
      "new tx found at frame 377 [[  2. 129. 149.   4.   0.]]\n",
      "done!\n",
      "new tx found at frame 378 [[  2. 126. 149.   3.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "Choose spot for frame 380\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  2. 126. 151.   3.   0.]]\n",
      "Enter 1 for spot [[  7. 131. 151.   1.   0.]]\n",
      "None0\n",
      "done!\n",
      "new tx found at frame 381 [[  3. 125. 152.   3.   0.]]\n",
      "Choose spot for frame 382\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  2. 126. 151.   2.   0.]]\n",
      "Enter 1 for spot [[  7. 129. 152.   1.   0.]]\n",
      "None0\n",
      "new tx found at frame 382 [[  3. 125. 152.   3.   0.]]\n",
      "done!\n",
      "new tx found at frame 383 [[  2. 126. 150.   1.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 385 [[  2. 127. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 386 [[  2. 126. 151.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 387 [[  2. 126. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 388 [[  2. 127. 151.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 389 [[  2. 125. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 390 [[  2. 127. 148.   2.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 392 [[  2. 125. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 393 [[  2. 126. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 394 [[  3. 126. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 395 [[  2. 125. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 396 [[  2. 125. 149.   2.   0.]]\n",
      "Choose spot for frame 397\n",
      "done!\n",
      "done!\n",
      "not found (not close to last location)\n",
      "\n",
      "Enter 0 for spot [[  3. 126. 152.   1.   0.]]\n",
      "Enter 1 for spot []\n",
      "None0\n",
      "new tx found at frame 397 [[  2. 125. 149.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 398 [[  3. 127. 153.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 399 [[  2. 127. 150.   1.   0.]]\n",
      "Choose spot for frame 400\n",
      "done!\n",
      "done!\n",
      "\n",
      "Enter 0 for spot [[  2. 127. 151.   2.   0.]]\n",
      "Enter 1 for spot [[  6. 127. 145.   2.   0.]]\n",
      "None0\n",
      "new tx found at frame 400 [[  2. 127. 150.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 401 [[  2. 127. 152.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 402 [[  2. 129. 152.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 403 [[  2. 126. 152.   1.   0.]]\n",
      "done!\n",
      "not found (not close to last location)\n",
      "done!\n",
      "new tx found at frame 422 [[  4. 121. 148.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 424 [[  3. 120. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 426 [[  4. 127. 147.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 461 [[  7. 129. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 480 [[  7. 126. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 534 [[  3. 131. 150.   2.   0.]]\n",
      "done!\n",
      "new tx found at frame 535 [[  4. 130. 148.   2.   0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "new tx found at frame 795 [[  4. 121. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 796 [[  4. 121. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 797 [[  4. 121. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 800 [[  4. 120. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 802 [[  4. 121. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 803 [[  4. 121. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 806 [[  4. 121. 148.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 808 [[  4. 121. 149.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 810 [[  5. 129. 145.   1.   0.]]\n",
      "done!\n",
      "new tx found at frame 811 [[  5. 128. 145.   2.   0.]]\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(potentialSpots)):\n",
    "    timepoint= potentialSpots[j][0]\n",
    "    spotTemp = potentialSpots[j][1]\n",
    "    if len(spotTemp)>1:\n",
    "        print('Choose spot for frame '+str(timepoint))\n",
    "        nw1 = findTxSite(selectedThreshold, sequenceCell, reference_spot, cellNumber, timepoint, label(cell_label_clean).astype(bool), spotTemp[0], 1, 3, 1, reorderTF = False)\n",
    "        nw2 = findTxSite(selectedThreshold, sequenceCell, reference_spot, cellNumber, timepoint, label(cell_label_clean).astype(bool), spotTemp[1], 1, 3, 1, reorderTF = False)\n",
    "        choosenspot = input(print('\\nEnter 0 for spot '+str(nw1)+str('\\nEnter 1 for spot ')+str(nw2)))\n",
    "        #check within limits before choosing\n",
    "        if choosenspot==0:\n",
    "            if checkWithinLimits(nw1[0][:3],  limitsz, limitsy, limitsx):\n",
    "                print('Not within limits')\n",
    "            else:\n",
    "                newtxs=nw1\n",
    "                print('new tx found at frame '+str(timepoint), newtxs)\n",
    "        elif choosenspot==1:\n",
    "            if checkWithinLimits(nw2[0][:3],  limitsz, limitsy, limitsx):\n",
    "                print('Not within limits')\n",
    "            else:\n",
    "                newtxs=nw2\n",
    "                print('new tx found at frame '+str(timepoint), newtxs)\n",
    "    elif len(spotTemp)==1:       \n",
    "        newtxs = findTxSite(selectedThreshold, sequenceCell, reference_spot, cellNumber, timepoint, label(cell_label_clean).astype(bool), spotTemp, 1, 3, 1, reorderTF = False)\n",
    "    if newtxs.size!=0:\n",
    "        print('new tx found at frame '+str(timepoint), newtxs)\n",
    "        potentialTxsFinal.loc[np.logical_and(potentialTxsFinal['cluster_id']==txid,potentialTxsFinal['frame']==timepoint),['z','y','x','mrna']]=newtxs[:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3479a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTxSite(selectedThreshold, sequenceCell, reference_spot,cellNumber, t,Tx_label_clean, lastLocation, bETA, gAMA=5, numCs=2, reorderTF = False):\n",
    "    spots_T, clusters_T, _ = getSpotAndClusters(sequenceCell,\n",
    "                                             reference_spot, \n",
    "                                             cellnumber=cellNumber, \n",
    "                                             startTime=t,\n",
    "                                             stopTime=t+1, \n",
    "                                             thresholdManual=selectedThreshold, \n",
    "                                             beta=bETA, \n",
    "                                             gamma=gAMA,\n",
    "                                             numberOfSpots=numCs,\n",
    "                                             radiusCluster=400, \n",
    "                                             voxelSize=voxelRadius, \n",
    "                                             objectSize=objectRadius,\n",
    "                                             reorder=reorderTF,\n",
    "                                             extensionMov='.tif',\n",
    "                                             showProgress=False)\n",
    "\n",
    "    if len(clusters_T[0])>3*len(spots_T[0]):\n",
    "        print(len(spots_T[0]))\n",
    "        print(len(clusters_T[0]))\n",
    "        print('beta very low! Increase the beta!')\n",
    "        \n",
    "    mask_in_frames = Tx_label_clean[clusters_T[0][:,1], clusters_T[0][:,2]]\n",
    "    missingTx0 = clusters_T[0][mask_in_frames]\n",
    "    if missingTx0.size!=0:\n",
    "        idxs = np.where(np.sum(np.abs(missingTx0[:,0:3] - lastLocation), axis=1)<=1)[0]\n",
    "        if idxs.size!=0:\n",
    "            missingTx = mergeTxSites(missingTx0[idxs,:])\n",
    "            return missingTx\n",
    "        else:\n",
    "            print('not found (not close to last location)')\n",
    "            return missingTx0[idxs,:]\n",
    "    else:\n",
    "        print('not found (not in mask)')\n",
    "        return missingTx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7455936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkWithinLimits(point, limz, limy, limx):\n",
    "    if point[0]<=limz[1] and point[0]>=limz[0]:\n",
    "        zz=1\n",
    "    else:\n",
    "        zz=0\n",
    "    if point[1]<=limy[1] and point[1]>=limy[0]:\n",
    "        yy=1\n",
    "    else:\n",
    "        yy=0\n",
    "    if point[2]<=limx[1] and point[2]>=limz[0]:\n",
    "        xx=1\n",
    "    else:\n",
    "        xx=0\n",
    "    if zz+yy+xx==3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9eb90c12",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1585477363.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def checkClosestPos()\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def checkClosestPos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b57de65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Traceback (most recent call last):\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 487, in advance_eventloop\n",
      "    eventloop(self)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/ipykernel/eventloops.py\", line 145, in loop_qt\n",
      "    el.exec() if hasattr(el, \"exec\") else el.exec_()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/_qt/widgets/qt_scrollbar.py\", line 69, in mouseMoveEvent\n",
      "    return super().mouseMoveEvent(event)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/_qt/widgets/qt_dims_slider.py\", line 142, in _value_changed\n",
      "    self.dims.set_current_step(self.axis, value)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/components/dims.py\", line 290, in set_current_step\n",
      "    self.current_step = full_current_step\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/utils/events/evented_model.py\", line 333, in __setattr__\n",
      "    emitter(value=after)  # emit event\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/utils/events/event.py\", line 763, in __call__\n",
      "    self._invoke_callback(cb, event if pass_event else None)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/utils/events/event.py\", line 788, in _invoke_callback\n",
      "    cb(event)\n",
      "  File \"/tmp/ipykernel_8756/1350257884.py\", line 81, in <lambda>\n",
      "    lambda event: set_pts_features(bigfish_Spots, bigfish_clusters, pts_coordinates, cluster_coordinate,image_layer.data.ndim, event.value)\n",
      "  File \"/tmp/ipykernel_8756/3520751948.py\", line 24, in set_pts_features\n",
      "    pts_layer.data = getDetectedPointsForFrame(pts_coordinates,frameNumber)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/layers/points/points.py\", line 554, in data\n",
      "    self._set_data(data)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/layers/points/points.py\", line 629, in _set_data\n",
      "    self._update_dims()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/layers/base/base.py\", line 780, in _update_dims\n",
      "    self._clear_extent()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/layers/base/base.py\", line 854, in _clear_extent\n",
      "    self.refresh()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/layers/base/base.py\", line 1298, in refresh\n",
      "    self.events.set_data()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/utils/events/event.py\", line 763, in __call__\n",
      "    self._invoke_callback(cb, event if pass_event else None)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/utils/events/event.py\", line 790, in _invoke_callback\n",
      "    cb()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/_vispy/overlays/bounding_box.py\", line 28, in _on_bounds_change\n",
      "    self.node.set_bounds(bounds[::-1])\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/_vispy/visuals/bounding_box.py\", line 98, in set_bounds\n",
      "    self._set_bounds_2d(vertices)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/napari/_vispy/visuals/bounding_box.py\", line 59, in _set_bounds_2d\n",
      "    self.line2d.set_data(pos=vertices, connect=edges)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/visuals/line/line.py\", line 189, in set_data\n",
      "    self.update()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/scene/node.py\", line 331, in update\n",
      "    self.events.update()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/util/event.py\", line 453, in __call__\n",
      "    self._invoke_callback(cb, event)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/util/event.py\", line 471, in _invoke_callback\n",
      "    _handle_exception(self.ignore_callback_errors,\n",
      "  << caught exception here: >>\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/util/event.py\", line 469, in _invoke_callback\n",
      "    cb(event)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/visuals/visual.py\", line 652, in _subv_update\n",
      "    self.update()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/scene/node.py\", line 334, in update\n",
      "    c.update(node=self)\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 202, in update\n",
      "    super(SceneCanvas, self).update()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/app/canvas.py\", line 448, in update\n",
      "    self._backend._vispy_update()\n",
      "  File \"/home/rachel/anaconda3/envs/bigfishLive/lib/python3.8/site-packages/vispy/app/backends/_qt.py\", line 480, in _vispy_update\n",
      "    self.update()\n",
      "RuntimeError: wrapped C/C++ object of type CanvasBackendDesktop has been deleted\n",
      "ERROR: Invoking <bound method CompoundVisual._subv_update of <BoundingBox at 0x7524e92bdc40>> for Event\n"
     ]
    }
   ],
   "source": [
    "newtxs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1af0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
